{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3f34d8-feb7-4e70-a3b2-28b2ecde23b8",
   "metadata": {},
   "source": [
    "# 构建一个提取链\n",
    "- 项目教程地址：\n",
    "    - https://python.langchain.com/docs/tutorials/extraction/\n",
    "- DeepSeek在LangChain中的集成包文档：\n",
    "    - https://python.langchain.com/api_reference/deepseek/chat_models/langchain_deepseek.chat_models.ChatDeepSeek.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5a699-1b13-4975-bb4c-556028e48229",
   "metadata": {},
   "source": [
    "- 在这个教程中， 我们将会使用大模型的tool_calling功能来从非结构化的文本中提取结构化的信息，这个教程也会展示如何使用少样本提示（few-shot prompting）来提升性能。\n",
    "- **此教学需要langchain-core版本在0.3.20以上，并且需要大模型工具具备tool calling功能**\n",
    "    - 以下是如何查看自己的langchain-core版本的两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84c79bc-23bf-49f1-9de1-3ab79b75cfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.44\n"
     ]
    }
   ],
   "source": [
    "import langchain_core\n",
    "print(langchain_core.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d2c4f-b30f-4195-8d9b-93b63fc61561",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac2e3d-13be-4dde-9aab-d3622d6fb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新版本\n",
    "pip install --upgrade langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d6122-3547-4a2f-ad4e-ef4c2429b317",
   "metadata": {},
   "source": [
    "## 环境配置\n",
    "1. 需要Jupyter Notebook\n",
    "2. 安装\n",
    "    - pip install --upgrade langchain-core\n",
    "3. LangSmith配置见以下代码：\n",
    "    - 我分享在Github中的Langchain项目下的其他项目有解释，0基础请从头看起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c40ddd-d0ac-4166-8aea-d547e9cdb101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os \n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2de7c4-c80b-4df2-a0e9-6c74da6e3ba3",
   "metadata": {},
   "source": [
    "## 数据模式定义\n",
    "- 首先我们需要定义我们想要从文本中提取数据的结构是怎样的\n",
    "- 我们将会使用Pydantic来定义一个样例模型来提取个人信息，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b441f7d-68d1-4092-b073-0cb1f364cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional \n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    \n",
    "    # ^ 这是Person实体的文档字符串\n",
    "    # 这个文档字符串会被发送给大模型作为Person数据结构的描述内容\n",
    "    # 这将帮助优化文本提取结果\n",
    "    \n",
    "    # 提示\n",
    "    # 1. 下面的每个字段都是可选项 - 这允许大模型不提取该字段。 \n",
    "        # 提高灵活性，在文本没有提供该字段的时候允许大模型不提取该字段。\n",
    "    # 2. 每个字段都包含描述属性 - 大模型在提取内容时会参考描述内容\n",
    "        # 好的描述能够帮助优化提取结果\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a0024-970b-4f8b-9d44-3a2463113056",
   "metadata": {},
   "source": [
    "- Schema（模式）为什么使用Optional模块？\n",
    "    - Pydantic 使用字段的类型注解来验证输入数据。如果注解是 name: str，Pydantic 会要求输入必须是字符串，None 会导致验证失败。\n",
    "    - 用 Optional[str]，Pydantic 明确知道这个字段允许 None，并在解析时接受 None 作为合法值。\n",
    "- 为Schema写好注释非常重要，同时确保在没有相关信息时不会让大模型强制输出结果，这样才能够使得结果更加准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473b7a6-45d8-41c3-9007-bec999cf589c",
   "metadata": {},
   "source": [
    "# 2.提取器\n",
    "- 基于创建好的数据输出模式创建信息提取器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bcfd88-d3f8-4d25-a1f9-57ac935d381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 定义一个个性化的提示词来提供指示和任何额外的上下文。\n",
    "# 1) 你可以添加样例到提示词模版中来优化提取质量。\n",
    "# 2) 引入额外的参数把上下文考虑进去。（例如文档的Metadata属性）\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm.\"\n",
    "            \"Only extract relevant information from the text.\"\n",
    "            \"If you do not know the value of an attribute asked to extract,\"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        # 请查看How-to文档来优化参考样例的性能\n",
    "        (\"human\",\"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad19393-0702-4138-9ddf-587522d7e15c",
   "metadata": {},
   "source": [
    "- 我们需要使用支持function或者tool calling的大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81263bb3-9da4-43a4-a04a-0cf0a4d94ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your DeepSeek API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os \n",
    "# 前置需要进入deepseek官网注册并生成API_KEY，记得保存好，否则丢失后需要重新生成。\n",
    "# 这一行检查程序是否已经有 Deepseek API 密钥。如果没有，就需要用户手动输入。\n",
    "if not os.getenv(\"DEEPSEEK_API_KEY\"):\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\"Enter your DeepSeek API key: \")\n",
    "\n",
    "# 配置接口参数，创建语言模型的实例\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\", #指定使用的模型\n",
    "    temperature=0, #控制生成文本的随机性\n",
    "    max_tokens=None, #生成的最大token数限制\n",
    "    timeout=None, #请求超时时间\n",
    "    max_retries=2, #请求失败时的最大重试次数\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8795102-0618-42ae-b795-513b70522397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型数据输出实例，按照Person的数据结构输出结果文本\n",
    "structured_llm = llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1268f2a6-1e1f-4151-90bf-98e5560d387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Vincent', hair_color='black', height_in_meters='1.83')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Vincent is 6 feet tall and has black hair.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f902e2-f340-4f3e-8a2e-c37078e8f52a",
   "metadata": {},
   "source": [
    "# 3.抽取多个实体\n",
    "- 在大部分情况下，你应该需要提取很多实体，而不仅仅只是一个\n",
    "- 这可以通过在pydantic中嵌套大模型来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5958423-5e00-4287-bb61-39b40b96dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional \n",
    "\n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    \n",
    "    # 实体Person的文档字符串\n",
    "    # 这个文档字符串会被发给大模型作为Person数据输出结构的描述，这能够帮助优化数据提取结果\n",
    "    \n",
    "    # 提示：\n",
    "    # 1. 每个字段都是可选的 -- 这允许大模型不提取这个字段，在某些信息不存在的情况下\n",
    "    # 2. 每个字段都有描述 -- 这个描述会被大模型采用\n",
    "    # 好的描述能够帮助优化提取结果\n",
    "    \n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "    \n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extract data about people.\"\"\"\n",
    "    \n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc746a42-7cb1-4c44-9767-af4f47dfdae7",
   "metadata": {},
   "source": [
    "1. 为什么导入 List？\n",
    "    - List 来自 typing，用于指定 people 字段的类型为 列表。\n",
    "    - 在 Data 类中，people 字段是 List[Person]，表示它是一个由 多个 Person 对象 组成的列表。\n",
    "    - 这意味着提取结果可以包含 多个人的信息，而不仅仅是单个 Person 实例。\n",
    "2. people 字段的写法目的，以及逻辑是什么？\n",
    "- 目的：\n",
    "    - people 这个字段的目的是 允许提取多个 Person 实体，而不仅仅是一个。这样，当数据中包含多个不同的人的信息时，可以将所有人的信息结构化地存储在 people 这个列表中。\n",
    "- 逻辑：\n",
    "    - people: List[Person] 说明 Data 类的 people 字段是一个包含 多个 Person 实例的列表。\n",
    "    - pydantic 会根据 Person 这个数据结构，对 people 里的每一个 Person 进行 验证 和 格式化，确保数据符合定义的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1536c81d-6e8f-4054-ac10-f839c15bb657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.83'), Person(name='Anna', hair_color='black', height_in_meters=None), Person(name='Vincent', hair_color='red', height_in_meters='1.8')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "text = \"My name is Jeff, my hair is balck and i am 6 feet tall. Anna has the same color hair as me. Vincent is 1.8 meters and has red hair.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec8f7b-70ec-4d6b-b015-e0e838509fb3",
   "metadata": {},
   "source": [
    "- 当输出模式适应多实体文本数据提取，这也允许大模型提取非实体如果文本中没有相关信息，最终大模型会输出一个空的列表。\n",
    "- 这通常是件好事。它允许为实体指定必需的属性，而不一定强制模型检测到该实体。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92e210-e95e-4032-ac1f-7b9784d7f974",
   "metadata": {},
   "source": [
    "# 4.参考样例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb688a3-8319-42eb-bcc1-41d13010105d",
   "metadata": {},
   "source": [
    "- 大语言模型的表现可以被引导通过少样本提示（few-shot prompting）.这样聊天模型就可以拿到一系列成对的输入和回答的模型，这些模型展示了我们想要的结果。\n",
    "- 例如，我们可以传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f09e89-666d-4b2b-a62e-1a8b8cc3cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
    "    {\"role\": \"user\", \"content\": \"3 🦜 4\"},\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88822684-ac17-40fe-8dc1-e0d661fcb0fe",
   "metadata": {},
   "source": [
    "1. 代码解读：\n",
    "    1. messages 是一个对话历史的列表，其中包含了用户 (\"role\": \"user\") 和助手 (\"role\": \"assistant\") 之间的交互。\n",
    "    2. 在前几个示例中，用户输入 \"2 🦜 2\"，助手输出 \"4\"，用户输入 \"2 🦜 3\"，助手输出 \"5\"。\n",
    "    3. 这个 🦜（鹦鹉）符号可能被用作自定义运算符，模型需要从上下文中推断其含义，看起来它代表的是加法（2 + 2 = 4, 2 + 3 = 5）。\n",
    "    4. response = llm.invoke(messages) 让 LLM 继续这个对话，针对 \"3 🦜 4\" 生成一个合理的输出，预计它会返回 \"7\"，因为之前的模式表明 🦜 可能意味着加法。\n",
    "2. 目的：\n",
    "    1. 这个写法的目的是提供一些示例对话，让模型学会如何处理 🦜 这个符号的含义，从而在新输入 \"3 🦜 4\" 时推理出正确的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50c0e5-a746-4540-b670-d5a0f79ebb54",
   "metadata": {},
   "source": [
    "- 不同的大模型服务商对消息排序会有不同的需求。一些接受如下的模型消息排序，例如：\n",
    "    - 用户消息\n",
    "    - 工具调用的AI消息\n",
    "    - 返回的工具消息 \n",
    "   另外一些模型会要求包含了特定顺序的最终的AI指令。\n",
    "- LangChain有一个实用性的方法叫做 tool_example_to_message，这个方法会生成一个大部分大模型服务商都会接受的顺序。它简化了结构化少样本的生成，仅仅只要求所调用工具的Pydantic定义的数据输出结构。\n",
    "- 让我们来尝试一下。我们可以把一堆输入字符串和想要的Pydantic对象转变成有序的消息，这样大模型就能顺利生成这个结果。 LangChain将会在底层将too calls整理成服务商所需要的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f553be57-b4f9-4579-843c-51ddd0ca44a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/ipykernel_9873/1222595702.py:23: LangChainBetaWarning: The function `tool_example_to_messages` is in beta. It is actively being worked on, so the API may change.\n",
      "  messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n",
    "        Data(people=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"Fiona traveled far from France to Spain.\",\n",
    "        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n",
    "    ),\n",
    "\n",
    "]\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call in examples:\n",
    "    if tool_call.people:\n",
    "        # 对于一部分大模型，最终的结果是可选的\n",
    "        ai_response = \"Detected people.\"\n",
    "    else:\n",
    "        ai_response = \"Detected no people.\"\n",
    "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84613ad6-704f-4e0b-a392-cc77f12cd9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"The ocean is vast and blue. It's more than 20,000 feet deep.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'bc4ae030-defb-437c-87ea-90354ad53db9', 'type': 'function', 'function': {'name': 'Data', 'arguments': '{\"people\":[]}'}}]}, response_metadata={}, tool_calls=[{'name': 'Data', 'args': {'people': []}, 'id': 'bc4ae030-defb-437c-87ea-90354ad53db9', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='You have correctly called this tool.', tool_call_id='bc4ae030-defb-437c-87ea-90354ad53db9'),\n",
       " AIMessage(content='Detected no people.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Fiona traveled far from France to Spain.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '674c04fa-33a6-45cd-ada0-da1473877eb7', 'type': 'function', 'function': {'name': 'Data', 'arguments': '{\"people\":[{\"name\":\"Fiona\",\"hair_color\":null,\"height_in_meters\":null}]}'}}]}, response_metadata={}, tool_calls=[{'name': 'Data', 'args': {'people': [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]}, 'id': '674c04fa-33a6-45cd-ada0-da1473877eb7', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='You have correctly called this tool.', tool_call_id='674c04fa-33a6-45cd-ada0-da1473877eb7'),\n",
       " AIMessage(content='Detected people.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae713939-6697-46f3-a1f2-bc1346e81af8",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "1. for txt, tool_call in examples:\n",
    "    - 这里的 examples 是一个包含多个元组的列表。每个元组里有两个元素，第一个是文本（字符串），第二个是结构化数据（一个 Data 对象）。\n",
    "    - 在循环中，txt 被赋值为文本内容，而 tool_call 被赋值为对应的 Data 对象。\n",
    "2. if tool_call.people:\n",
    "    - 这里的判断逻辑是检查 tool_call 对象中的 people 列表是否非空。\n",
    "    - 如果 people 列表中存在至少一个 Person 实例，则条件为 True，表示文本中检测到了人物；否则条件为 False。\n",
    "3. tool_example_to_messages：\n",
    "    - 这是从 langchain_core.utils.function_calling 模块中导入的一个函数，用于将一个工具调用示例转换成一系列格式化的消息。\n",
    "    - 它会把给定的文本、工具调用输出（这里是一个 Data 对象的列表）以及 AI 响应转换为符合 LangChain 消息格式的列表。\n",
    "4. messages.extend(...)：\n",
    "    - messages 是一个 Python 列表，.extend() 是列表的方法，用于将另一个列表中的所有元素添加到 messages 列表末尾。\n",
    "    - 这样，所有转换后的消息都会被追加到 messages 列表中，形成一个完整的消息序列。\n",
    "\n",
    "5. 综合来说，这段代码遍历示例数据，为每个文本与其对应的结构化数据（Data 对象）生成一组消息，并根据是否检测到人物设置不同的 AI 响应，最后将所有生成的消息追加到 messages 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec80aed-c869-401d-a78d-a7f90a29bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The ocean is vast and blue. It's more than 20,000 feet deep.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (bc4ae030-defb-437c-87ea-90354ad53db9)\n",
      " Call ID: bc4ae030-defb-437c-87ea-90354ad53db9\n",
      "  Args:\n",
      "    people: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected no people.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Fiona traveled far from France to Spain.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (674c04fa-33a6-45cd-ada0-da1473877eb7)\n",
      " Call ID: 674c04fa-33a6-45cd-ada0-da1473877eb7\n",
      "  Args:\n",
      "    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected people.\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac60d938-01f6-4761-99a3-08c93e6991c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Earth', hair_color=None, height_in_meters=None)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_no_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
    "}\n",
    "\n",
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "structured_llm.invoke([message_no_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36e10a5a-a9cc-471a-a84d-83c094202122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(messages + [message_no_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50e4b9-39d8-4e4c-bd15-77ac7dbe00ba",
   "metadata": {},
   "source": [
    "- 以上可以对比有样本学习的情况和无样本学习的情况，有样本的情况下大模型学会了识别语句中是否有人的元素，无样本的情况下大模型直接将物质作为人的信息进行了输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2ecbe-b100-4740-bff0-300297418ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
