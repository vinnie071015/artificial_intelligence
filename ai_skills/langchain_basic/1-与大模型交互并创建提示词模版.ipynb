{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d2fe4-2a30-4520-ad71-3589ca52a56a",
   "metadata": {},
   "source": [
    "# 1. 项目地址  \n",
    "https://python.langchain.com/docs/tutorials/llm_chain/\n",
    "\n",
    "通过这个项目，你将获得的能力：  \n",
    "1.使用大语言模型  \n",
    "2.使用提示词模版  \n",
    "3.使用LangSmith来调试和追踪你的应用问题  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1c638-2502-4842-bce5-924a53d36395",
   "metadata": {},
   "source": [
    "# 2. 代码环境设置\n",
    "Jupyter Notebook or Jupyter Lab\n",
    "自行找文档下载安装哈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12822b-bbbb-4231-abfe-bd69a517a765",
   "metadata": {},
   "source": [
    "## 安装langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e742a-22c2-42c2-a7cd-8446cbc06933",
   "metadata": {},
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb97dc3-7cf4-45ce-b105-12f1dcf2a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39aff6-ee88-490e-9c11-7f0b5e3ba7d9",
   "metadata": {},
   "source": [
    "# 3. 设置Langsmith\n",
    "1. LangSmith是做什么的  \n",
    "    - 跟踪调试：记录模型运行过程，定位问题。\n",
    "    - 测试评估：批量测试模型表现，支持自定义标准。\n",
    "    - 实时监控：跟踪生产环境性能和用户交互。\n",
    "    - Prompt 管理：优化和管理提示词，支持版本控制。  \n",
    "    \n",
    "2. Address：\n",
    "    https://smith.langchain.com/onboarding?organizationId=d33de966-2acd-4e99-884a-4a51a8600109&step=1\n",
    "3. 其他:\n",
    "    - 需要注册\n",
    "    - 需要生成API key用来交互，服务在云端\n",
    "    - 如没有监控需求，也可以选择不启用这个监控服务，对后续无影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a359b86d-a3f4-4033-b94c-99b4fc45ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# 代码\n",
    "\n",
    "import getpass\n",
    "import os  \n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4300e2-cc7c-417d-ad63-b1f6ca313f62",
   "metadata": {
    "tags": []
   },
   "source": [
    "**代码解释**\n",
    "1. getpass：getpass 是一个用于安全输入密码或敏感信息的工具。它的主要功能是让用户在终端输入内容时不回显（即输入时不会显示字符，通常用于密码输入）。\n",
    "2. os：os 模块提供了与操作系统交互的功能，包括文件操作、路径处理和环境变量管理等。\n",
    "3. os.environ[\"LANGSMITH_TRACING\"] = \"true\" 用来激活LangSmith服务，在后续的Langchain模块中会检测这个环境变量是否启用，如果启用会和LangSmith服务进行交互进而开启监控。\n",
    "4. os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "    1. 用来拿到LangSmith的API Key\n",
    "    2. getpass.getpass() 会提示用户在终端输入内容（默认提示是 \"Password: \"），输入的内容不会显示在屏幕上\n",
    "    3. Appkey需要注册账号，然后在网站内生成即可，也可以选择不启用这个监控服务，跳过即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321239e-841b-4a14-b60c-0ec87097adc9",
   "metadata": {},
   "source": [
    "# 4. 使用大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a0cda-94d3-435e-bc44-21eb24902de8",
   "metadata": {},
   "source": [
    "**安装langchain的集成**  \n",
    "pip install -qU \"langchain-deepseek\"\n",
    "\n",
    "- 安装Deepseek的Langchain扩展，用于和Deepseek接口进行交互。\n",
    "- Langchain也可以使用其他的模型，具体请直接查询官方文档代码，集成会有不一样，代码会有所变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79006fa1-141d-4bf9-a19e-b81dabc1be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your DeepSeek API key:  ········\n"
     ]
    }
   ],
   "source": [
    "# 前置需要进入deepseek官网注册并生成API_KEY，记得保存好，否则丢失后需要重新生成。\n",
    "# 这一行检查程序是否已经有 Deepseek API 密钥。如果没有，就需要用户手动输入。\n",
    "if not os.getenv(\"DEEPSEEK_API_KEY\"):\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\"Enter your DeepSeek API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b69249-e219-4cba-83c8-cc80f0894a31",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- os.getenv(key) 是 os 模块的一个函数，用于读取环境变量的值。\n",
    "- 如果环境变量 DEEPSEEK_API_KEY 已设置（比如通过终端的 export DEEPSEEK_API_KEY=\"your-key\"），它返回对应的值（字符串）。\n",
    "- 如果未设置或值为空，则返回 None。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560e98a2-6be7-4d33-be7d-76c8e148280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置接口参数，创建语言模型的实例\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",  # 指定使用的模型\n",
    "    temperature=0,  # 控制生成文本的随机性\n",
    "    max_tokens=None,  # 生成的最大 token 数限制\n",
    "    timeout=None,  # 请求超时时间\n",
    "    max_retries=2, # 请求失败时的最大重试次数\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a900a-1569-4c2f-b12f-2c79bbd4e687",
   "metadata": {},
   "source": [
    "- 让我们使用模型试试。ChatModels是LangChain中可运行的组件，这意味着他们会有一个标准接口来进行交户。唤起模型很简单，我们给.invoke方法传送一列消息即可达到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0153a1a8-199f-431b-937c-6bac37d9bd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!  \\n\\n(If you\\'re looking for a more formal greeting, you could also say \"Salve!\") 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 12, 'total_tokens': 38, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 12}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-4b103a31-b533-4d6a-8437-5d55c5b447fd-0', usage_metadata={'input_tokens': 12, 'output_tokens': 26, 'total_tokens': 38, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89ebd5-38e3-409d-badd-e5263a90614a",
   "metadata": {},
   "source": [
    "- 注意，大语言模型会接受消息对象作为输入然后生成消息对象作为输出。除了文本内容外，消息对象也可以表达交流角色并包含重要数据，例如工具调用和字数统计。\n",
    "\n",
    "- LangChain也支持聊天模型的输入通过字符串模式或者OpenAI 格式。以下是一下例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "431185a9-edf4-4b13-ac16-78456162fc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 4, 'total_tokens': 15, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 4}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-cbd59df7-eccf-4005-a67a-2878f9fb85e7-0', usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello\")\n",
    "llm.invoke([{\"role\":\"user\",\"content\":\"Hello\"}])\n",
    "llm.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fcd8c10-4c7a-4eef-aa83-ab4f756adc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 4, 'total_tokens': 15, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 4}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd36534c-0381-4ef0-a5bf-50ad38781363-0', usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce9c60e8-bca1-40f8-b33a-4290e468eaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 4, 'total_tokens': 15, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 4}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-fe1f08eb-146a-4b76-806e-d71137c72bea-0', usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([{\"role\":\"user\",\"content\":\"Hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3436806-00cd-46e6-aef9-d3e9fabe3140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 4, 'total_tokens': 15, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 4}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-65d3613b-51be-4613-b4d6-ae2374ef3277-0', usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e5462-c338-45ee-ab1e-964f1552bc0e",
   "metadata": {},
   "source": [
    "# 5. 流式处理stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732a25b-5a6e-4be7-837d-9eb5cec52d5f",
   "metadata": {},
   "source": [
    "- 因为聊天模型是可运行的组件-Runnables，他们有一个标准的接口，这个接口包含异步和流式调用模型。这就使得我们可以使用流式的方式处理单个字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "062207a0-bf73-4a9c-bb43-f10b036dd151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseChatModel.stream at 0x7f7b218af660>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.stream(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c19c95a-6eef-4a94-aaeb-a78508485e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||"
     ]
    }
   ],
   "source": [
    "# 流式处理\n",
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32738cc5-9c5c-4830-9376-5d96e58a3c7f",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- 通过 llm.stream(messages) 调用语言模型的流式输出方法，并用 for 循环迭代处理返回的每个 token。\n",
    "- stream 是语言模型提供的一个方法，用于以流式（streaming）方式生成输出。\n",
    "- 与一次性返回完整结果的 invoke 不同，stream 返回一个迭代器（iterator）或生成器（generator），逐步生成并返回模型输出的每个 token。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101c7d7-244e-450e-b0b9-2a9ef55d71cf",
   "metadata": {},
   "source": [
    "# 6. 提示词模版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d536384b-380c-4567-9a9e-55eae0107127",
   "metadata": {},
   "source": [
    "- 我们把一列信息直接给到大语言模型。这一列信息一般由用户输入和应用逻辑共同组成。这个应用逻辑通常拿到原始的用户输入并把这个输入转化成一组组织好的消息准备传送给大语言模型。一般的用户信息形式转换涉及结合用户输入添加系统信息或者构建一个模版。\n",
    "- LangChain就是这样来设计提示词模版概念来帮助实现这一转化过程。首先拿到用户的原始输入信息，然后转化为一个可以直接传输给大模型的提示词模版。\n",
    "- 我们在这里构建一个提示词模版样例，这将会使用两个用户变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "422d9fd8-2d79-42b4-b96e-c7567280903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个提示模板，用于将用户输入的英文文本翻译成指定语言并传递给大模型。\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",system_template),(\"user\",\"{text}\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea336e-9d68-4429-8823-4932f4abf60b",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- ChatPromptTemplate 是 LangChain 提供的一个工具，用于构建结构化的对话提示模板。\n",
    "- 它特别适合与支持聊天格式的语言模型（如 ChatDeepSeek、ChatOpenAI）配合使用，允许定义多角色消息（如系统消息、用户消息）。\n",
    "- prompt_template 是一个可重用的模板对象，允许动态填入 {language} 和 {text} 的值，生成完整的提示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b7ad4-51eb-4dd0-9cff-4cb2dfe124e6",
   "metadata": {},
   "source": [
    "- 注意，ChatPromptTemplate支持多种消息类型在单一模版中。我们将“language”参数嵌入到“system”消息中，将“text”嵌入到了“user”消息中。\n",
    "- 这个提示词模版的输入是一个字典，我们下面使用这个模版看看能生成什么结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dc1a287-6141-4005-bf71-066bde850529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这一步只是替换language和text占位符的内容为具体的值，\n",
    "# 后续可以使用prompt作为最终提示词来提交给大模型使用\n",
    "# prompt_template在这里就成立一个包含参数的灵活的提示词模版了\n",
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fdafc7-1d15-4ce9-b235-daf4942ef727",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- invoke 是 ChatPromptTemplate 的方法，用于将占位符替换为具体值，生成一个具体的提示对象。\n",
    "- 输入是一个字典，键（language 和 text）对应模板中的占位符，值（\"Italian\" 和 \"hi!\"）是替换的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ebb8121-5991-495e-8a36-a1868e21cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b55aa-1431-4a6d-b37b-6afe3f23441d",
   "metadata": {},
   "source": [
    "**代码解释**\n",
    "- 调用 prompt 对象的 to_messages() 方法，返回一个消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b4e18e1-6d3c-4820-89fd-3a747d6816c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "#与大模型交互，将提示词模版传输给大模型，并得到答案\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb665b2-f670-4384-9c0c-43fa5d0e5722",
   "metadata": {},
   "source": [
    "# 7. 总结\n",
    "- 到这里就结束了，你已经学会了如何创建你的第一个简单的大语言模型应用。又学习了如何与大语言模型进行交互，如何创造一个提示词模版，并且如何使用LangSmith去追踪你应用的运行情况。\n",
    "- 这对于你成一个专业的AI工程师只是隔靴搔痒，我们还有其他很多资源可供学习！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9670392-ebb5-4661-ab6a-5f3cf600b1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
