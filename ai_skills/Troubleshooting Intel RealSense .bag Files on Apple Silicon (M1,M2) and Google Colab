é€»è¾‘æ˜¯ï¼Œå°†.bagæ–‡ä»¶è½¬æ¢æˆRGB-Dï¼Œç„¶åç”¨pythonåŒ…è¿›è¡Œç©ºé—´æ¸²æŸ“ã€‚
- ç›®å‰çš„é—®é¢˜æ˜¯MèŠ¯ç‰‡ä¸Šçš„Realsense SDKä¸æ”¯æŒè§£ç .bagæ–‡ä»¶ï¼Œå¾—ä¸åˆ°å½•åˆ¶çš„æ•°æ®ã€‚

æ–¹æ³•ä¸€ï¼š
- åœ¨ç»ˆç«¯åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆæ”¾å¯¼å‡ºçš„ RGB/Depthï¼‰
ï¼ˆmkdir -p out_dirï¼‰

- ç”¨ rs-convert ä» .bag å¯¼å‡ºå¸§
ï¼ˆrs-convert -i my_scene.bag -c -d -p out_dir
ï¼‰

- åˆ›å»º Python æ–‡ä»¶ï¼ˆä¾‹å¦‚ view_rgbd.pyï¼‰
ï¼ˆnano view_rgbd.py
ï¼‰
python æ–‡ä»¶
- åœ¨ç»ˆç«¯è¿è¡Œ Python è„šæœ¬
ï¼ˆpython view_rgbd.py
ï¼‰

ç›®å‰çš„æ­¥éª¤æ˜¯æ£€æŸ¥æ–‡ä»¶ï¼Œä½†æ˜¯ã€rs-convert -i my_scene.bag -c -d -p out_dirã€‘æ²¡åŠæ³•åˆ°å¤„RGBå½©è‰²å¸§ã€‚
â€”â€”Librealsense åœ¨M1/M2ä¸Šä¸æ”¯æŒä».bagæ–‡ä»¶ä¸­è§£ç RGBå½©è‰²æµï¼Œæ‰€ä»¥rs-convertæ— æ³•å¯¼å‡ºRGBå¸§ã€‚

æ–¹æ³•äºŒï¼š
- æ‰“å¼€RealSense Viewer
- æ‰“å¼€.bagæ–‡ä»¶ 
- æ’­æ”¾æ£€æŸ¥
- å¯¼å‡ºRGBå¸§
Intel å®˜æ–¹ 2023 èµ·å·²ç»åœæ­¢ç»´æŠ¤ macOS ç‰ˆæœ¬çš„ RealSense SDKã€‚
M1/M2 ä¸Šåªèƒ½è·‘ä¸€ä¸ªã€Œå£³ã€ï¼Œä¸èƒ½æ‰§è¡Œå¯¼å…¥/å¯¼å‡ºã€‚

æ–¹æ³•ä¸‰ï¼š
Colab realsense SDK
Colabæ²¡æœ‰Rootæƒé™ï¼ŒSUDOéƒ½æ²¡æœ‰ã€‚

ğŸ“˜ Troubleshooting Intel RealSense .bag Files on Apple Silicon (M1/M2) and Google Colab

A practical guide based on real debugging experience
Covers: RealSense SDK, macOS ARM64 limitations, .bag decoding, RGB-D extraction, Colab cloud constraints, and recommended workflow.

ğŸš€ Background

I needed to capture and process RGB-D sequences from an Intel RealSense D435 camera for 3D perception tasks (e.g., Locate-3D inference, spatial reasoning, point cloud reconstruction).

Standard workflow:

Record .bag using rs-record

Convert .bag to RGB + Depth frames

Load the frames into Python/Colab for AI model testing

Sounds simple. In practice, on Apple Silicon (M1/M2) + Colab, this workflow breaks.

ğŸ§¨ Problem Summary
âœ… Depth conversion works

Using:

rs-convert -i my_scene.bag -d -p out_dir


Depth PNGs export successfully.

âŒ RGB conversion fails

Using:

rs-convert -i my_scene.bag -c -p out_dir


No RGB frames produced.

âŒ RealSense Viewer on macOS M1/M2 is broken

The app launches but:

No â€œFile â†’ Openâ€

No â€œExportâ€

No stream controls

Only a black screen and minimal UI

Viewer is a partial, unsupported build for macOS ARM64.

âŒ Colab cannot decode .bag

No USB access

No kernel/device permissions

No root privileges

No librealsense2 installation possible

ğŸ§  Root Cause Analysis
ğŸ“Œ 1. Intel RealSense SDK is not supported on macOS ARM64 (M1/M2)

No driver support

No firmware backend access

No decoding pipeline

Viewer is a crippled binary without full UI

ğŸ“Œ 2. rs-convert uses the same backend â†’ RGB stream cannot be decoded

Depth frames decode because they are raw depth packets.
Color frames require full RealSense pipeline.

ğŸ“Œ 3. Colab is a cloud VM

No /dev/bus/usb

No /dev/video*

You cannot patch kernel modules (uvcvideo)

No root â†’ cannot install RealSense drivers

Cannot load RealSense backend

âœ… Final Working Solution

The only stable workflow:

1ï¸âƒ£ Record .bag from a real machine
sudo rs-record -f my_scene.bag -t 10

2ï¸âƒ£ Export depth on any machine
rs-convert -i my_scene.bag -d -p out_dir/depth

3ï¸âƒ£ Export RGB on Windows/Linux x86_64

RealSense Viewer works correctly on Intel/AMD machines.

Steps:

Open viewer

File â†’ Open â†’ my_scene.bag

File â†’ Export â†’ Frames

Select PNG + Color stream

4ï¸âƒ£ Upload to Google Drive
rgb/*.png
depth/*.png
intrinsics.json
depth_scale.json

5ï¸âƒ£ In Colab, load and visualize easily
import cv2, glob
import matplotlib.pyplot as plt

rgb = cv2.imread(sorted(glob.glob("rgb/*.png"))[0])[:,:,::-1]
depth = cv2.imread(sorted(glob.glob("depth/*.png"))[0], cv2.IMREAD_UNCHANGED)

plt.subplot(1,2,1); plt.imshow(rgb); plt.axis('off')
plt.subplot(1,2,2); plt.imshow(depth, cmap='gray'); plt.axis('off')
plt.show()

âœ… Recommendations
If you're on Apple Silicon

Do not rely on RealSense SDK

Use .bag only for playback on x86_64 machines

For AI/3D processing

Use PNG + intrinsics

Use OpenCV/Open3D

Run inference on Colab where you have GPU

ğŸ“ Conclusion

RealSense SDK is fundamentally incompatible with Apple Silicon and cloud notebooks.
Once you understand the architectural constraints, the correct workflow becomes simple:

Record â†’ Export on x86 â†’ Process anywhere

ğŸ”— (Optional) Repository Structure Example
.
â”œâ”€â”€ README.md
â”œâ”€â”€ my_scene.bag
â”œâ”€â”€ export_scripts/
â”‚   â”œâ”€â”€ record_bag.py
â”‚   â”œâ”€â”€ view_rgbd.py
â”œâ”€â”€ exported_data/
â”‚   â”œâ”€â”€ rgb/
â”‚   â”œâ”€â”€ depth/
â”‚   â”œâ”€â”€ intrinsics.json
â”‚   â”œâ”€â”€ depth_scale.json
â””â”€â”€ colab_demo.ipynb


