{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d193b2-b2c1-4d73-bfc1-a1f7bb73a694",
   "metadata": {},
   "source": [
    "# Quickstart: Launch Local LangGraph Server\n",
    "本文档会帮你创建一个LangGraph app并在本地运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10638e46-155e-4a97-bbb5-109f79e80859",
   "metadata": {},
   "source": [
    "## 1.Set Up\n",
    "Python >= 3.11  \n",
    "LangGraph CLI: Requires langchain-cli[inmem] >= 0.1.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aedc3ca-5269-4990-aec4-6e6af1fee5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.9 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 13:04:33) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# check your python version\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749c32-48c0-451b-9a55-b80aee50efd4",
   "metadata": {},
   "source": [
    "# 2.Install the LangGraph CLI¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984b15b-ff34-4a20-ae06-2bd8a22592a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade \"langgraph-cli[inmem]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3712949d-701e-4032-9523-36e927abfe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph-cli\n",
      "Version: 0.1.89\n",
      "Summary: CLI for interacting with LangGraph API\n",
      "Home-page: https://www.github.com/langchain-ai/langgraph\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/zhengchengsheng/opt/anaconda3/envs/new_env/lib/python3.12/site-packages\n",
      "Requires: click\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langgraph-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311da7d3-36ec-40db-9e30-d1c5349eeeb3",
   "metadata": {},
   "source": [
    "# 3.Create a LangGraph App¶\n",
    "从[react-agent]创建一个新的app，这个模版是一个简单的agent，能够被灵活的扩展为很多工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7bbfe-b607-47a5-9dcd-5fcccb7ae88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langgraph new path/to/your/app --template react-agent-python\n",
    "# 终端命令，需要在终端中进行运行\n",
    "# 打开安装了CLI的环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff307b2-2999-4d8b-a898-4ca3eb093a29",
   "metadata": {},
   "source": [
    "# 4.Install Dependencies¶\n",
    "在新的Langgraph app的根目录下，在edit模式中安装依赖，这样本地变化能够被服务器使用。\n",
    "解释： \n",
    "1. 上一步从git拉取的app的文件\n",
    "2. 这一步是为了把app运行需要的依赖全部安装下来，是的后续的运行顺畅\n",
    "\n",
    "步骤：\n",
    "1. 先cd进到根目录\n",
    "2. 然后运行代码把依赖全部下载下来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483ba89-7fa8-4421-9016-28c2b95cb942",
   "metadata": {},
   "source": [
    "## pip install -e .\n",
    "1. -e : 表示“editable”（可编辑）模式。这是一个特殊的安装选项，告诉 pip 以开发模式安装包，而不是简单地复制到 Python 的 site-packages 目录。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e4e3b-7a5a-4243-910f-889f19e20d39",
   "metadata": {},
   "source": [
    "# 6.Create a .env file\n",
    "You will find a .env.example in the root of your new LangGraph app. Create a .env file in the root of your new LangGraph app and copy the contents of the .env.example file into it, filling in the necessary API keys:\n",
    "\n",
    "LANGSMITH_API_KEY=lsv2...\n",
    "TAVILY_API_KEY=tvly-...\n",
    "ANTHROPIC_API_KEY=sk-\n",
    "OPENAI_API_KEY=sk-...\n",
    "\n",
    "- 这里文件是隐藏的，在命令行中进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb22748-6f7a-4b4f-be60-bc94edc61ef1",
   "metadata": {},
   "source": [
    "# 7.Launch LangGraph Server¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529fc20-049b-4cad-a804-e06b4a5e7368",
   "metadata": {},
   "source": [
    "- 本地运行LangGraph API 服务器：\n",
    "    - 语法 ： langgraph dev\n",
    "    - 步骤：\n",
    "          1. 激活环境\n",
    "          2. 运行代码\n",
    "          3. 网页弹出\n",
    "\n",
    "- langgraph dev命令会在内存环境中运行LangGraph 服务器。这个模式非常适合开发和测试。对于生产目标，应该使用持久化存储端来运行LangGraph服务器。\n",
    "- 你可以使用langgraph up命令来测试你的应用，而不是langgraph dev。 这需要在电脑上安装docker。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf1272c-7787-49cd-801a-1527b22b5520",
   "metadata": {},
   "source": [
    "# 8.LangGraph Studio Web UI\n",
    "- LangGraph Stud Web is a visualization tool for connecting with the server side.\n",
    "- You can use Web for visualization,  interaction and debugging your app locally.\n",
    "- Use the URL provided from the output of langgraph dev command to test your graph.\n",
    "- By following command to change the port of your URL to the one of your custom host where your server being runned.\n",
    "    - https://smith.langchain.com/studio/baseUrl=http://127.0.0.1:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61496584-6c38-4f0c-900c-ce889849dddb",
   "metadata": {},
   "source": [
    "# 9.Test the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c7632-ebff-44e2-8470-591dfcb0cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ebc8ca-de64-4525-a0be-7017030cd748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "{'run_id': '1f0144fc-e9cc-6dbc-bf88-4c60061d8d2f', 'attempt': 1}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: updates...\n",
      "{'call_model': {'messages': [{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_0_a3823687-1d7f-4b9c-a250-e02442bc9271', 'function': {'arguments': '{\"query\":\"LangGraph\"}', 'name': 'search'}, 'type': 'function', 'index': 0}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 166, 'total_tokens': 184, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 166}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '5dd54a83-ade6-48f5-97d5-5b5f94070dec', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-6161d95c-d264-4552-b8f9-901ffbb7e6ea-0', 'example': False, 'tool_calls': [{'name': 'search', 'args': {'query': 'LangGraph'}, 'id': 'call_0_a3823687-1d7f-4b9c-a250-e02442bc9271', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 166, 'output_tokens': 18, 'total_tokens': 184, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}}]}}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: updates...\n",
      "{'tools': {'messages': [{'content': '[{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It\\'s particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9328032}, {\"title\": \"LangGraph: Build Stateful AI Agents in Python\", \"url\": \"https://realpython.com/langgraph-python/\", \"content\": \"Remove ads\\\\nLangGraph is a versatile Python library designed for stateful, cyclic, and multi-actor Large Language Model (LLM) applications. LangGraph builds upon its parent library, LangChain, and allows you to build sophisticated workflows that are capable of handling the complexities of real-world LLM applications.\\\\nBy the end of this tutorial, you’ll understand that: [...] These FAQs are related to the most important concepts you’ve covered in this tutorial. Click the Show/Hide toggle beside each question to reveal the answer.\\\\nWhat is LangGraph?Show/Hide\\\\nLangGraph is a Python library that helps you build stateful, cyclic, and multi-actor workflows for Large Language Model (LLM) applications, expanding upon LangChain’s capabilities.\\\\nHow does LangGraph differ from LangChain?Show/Hide [...] As you might have inferred from the name, LangGraph is all about implementing LLM applications as directed graphs. You can think of a directed graph as a sequence of instructions composed of nodes and edges, that tell you how to complete a task. In LangGraph, nodes represent actions that your graph can take, such as calling a function, and edges tell you which node to go to next.\\\\nTo understand this better, take a look at this directed graph:\", \"score\": 0.9197076}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Note\\\\nLooking for the JS version? See the JS repo and the JS docs.\\\\nLangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\\\nshell [...] LangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for: [...] While LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\\\nLangGraph Platform can help engineering teams:\", \"score\": 0.8991304}, {\"title\": \"LangGraph - Conceptual Guide - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/concepts/\", \"content\": \"LangGraph is an MIT-licensed open-source library, which we are committed to maintaining and growing for the community.\\\\nYou can always deploy LangGraph applications on your own infrastructure using the open-source LangGraph project without using LangGraph Platform.\\\\n\\\\nHigh Level¶ [...] LangGraph Platform¶\\\\nLangGraph Platform is a commercial solution for deploying agentic applications in production, built on the open-source LangGraph framework.\\\\nThe LangGraph Platform offers a few different deployment options described in the deployment options guide.\\\\nTip [...] LangGraph Server: The LangGraph Server is designed to support a wide range of agentic application use cases, from background processing to real-time interactions.\\\\nLangGraph Studio: LangGraph Studio is a specialized IDE that can connect to a LangGraph Server to enable visualization, interaction, and debugging of the application locally.\\\\nLangGraph CLI: LangGraph CLI is a command-line interface that helps to interact with a local LangGraph\", \"score\": 0.8430832}, {\"title\": \"LangGraph - LangChain\", \"url\": \"https://www.langchain.com/langgraph\", \"content\": \"Yes. LangGraph is an MIT-licensed open-source library and is free to use.\\\\nHow are LangGraph and LangGraph Platform different?\\\\nLangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\\\\nLangGraph (open source)\\\\nLangGraph Platform\\\\nFeatures\\\\nDescription [...] Simplify prototyping, debugging, and sharing of agents in our visual LangGraph Studio. Deploy your application with 1-click deploy with our SaaS offering or within your own VPC. Then, monitor app performance with LangSmith.\\\\nBuilt with LangGraph, trusted by the best.\\\\nLangGraph helps teams of all sizes, across all industries, build reliable AI\\xa0agents deployed in production. Hear customers tell their tales.\\\\nHear how industry leaders use LangGraph [...] Sathish Muthukrishnan\\\\nChief Information, Data and Digital Officer\\\\nLangGraph FAQs\\\\nDo I need to use LangChain to use LangGraph? What’s the difference?\\\\nNo. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents.\\xa0LangChain provides a standard interface to interact with models and other components, useful for straight-forward chains and retrieval flows.\\\\nHow is LangGraph different from other agent frameworks?\", \"score\": 0.82728493}, {\"title\": \"LangChain\", \"url\": \"https://www.langchain.com/\", \"content\": \"Build\\\\nLangChain is a composable framework to build with LLMs. LangGraph is the orchestration framework for controllable agentic workflows.\\\\nRun\\\\nDeploy your LLM applications at scale with LangGraph Platform, our infrastructure purpose-built for agents.\\\\nManage\\\\nDebug, collaborate, test, and monitor your LLM app in LangSmith - whether it\\'s built with a LangChain framework or not.\\\\nBuild your app with LangChain\", \"score\": 0.7999589}]', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'search', 'id': 'b8f7e8bc-b325-4f23-a658-ef667d6e7e00', 'tool_call_id': 'call_0_a3823687-1d7f-4b9c-a250-e02442bc9271', 'artifact': None, 'status': 'success'}]}}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: updates...\n",
      "{'call_model': {'messages': [{'content': 'LangGraph is a Python library designed for building stateful, multi-actor applications using Large Language Models (LLMs). It extends the capabilities of LangChain by providing tools for creating workflows and state machines to coordinate multiple AI agents or interactions. Here are some key points about LangGraph:\\n\\n1. **Purpose**: It helps developers build complex, stateful, and cyclic workflows for LLM applications, enabling more sophisticated agent and multi-agent systems.\\n\\n2. **Features**:\\n   - Supports directed graphs for defining workflows with nodes (actions) and edges (transitions).\\n   - Offers long-term memory and human-in-the-loop capabilities for reliable task handling.\\n   - Provides customizable architectures for agent orchestration.\\n\\n3. **Use Cases**: It is used for applications requiring advanced coordination between AI agents, such as background processing, real-time interactions, and debugging.\\n\\n4. **Open Source**: LangGraph is MIT-licensed and free to use, with additional commercial options like LangGraph Platform for scalable deployments.\\n\\n5. **Relation to LangChain**: While LangChain focuses on composable components for LLM applications, LangGraph specializes in low-level orchestration for agentic workflows.\\n\\nFor more details, you can explore the [LangGraph documentation](https://langchain-ai.github.io/langgraph/tutorials/introduction/) or its [GitHub repository](https://github.com/langchain-ai/langgraph).', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 280, 'prompt_tokens': 1736, 'total_tokens': 2016, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 1736}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '4b5f5278-4212-44d4-86f9-f9560656b837', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-4bfa2aa4-1f61-4ce4-b97a-2b3667e8ae30-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1736, 'output_tokens': 280, 'total_tokens': 2016, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}}]}}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "client = get_client(url=\"http://localhost:2024\")\n",
    "\n",
    "async for chunk in client.runs.stream(\n",
    "    None,  # Threadless run\n",
    "    \"agent\", # Name of assistant. Defined in langgraph.json.\n",
    "    input={\n",
    "        \"messages\": [{\n",
    "            \"role\": \"human\",\n",
    "            \"content\": \"What is LangGraph?\",\n",
    "        }],\n",
    "    },\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
